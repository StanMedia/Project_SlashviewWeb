<!DOCTYPE html><html><head><meta charset=utf-8 /><meta name=viewport content="width=device-width, initial-scale=1" /><link href=/.file/site.css rel=stylesheet /><script src=/.include/jquery/jquery.min.js></script></head><body><header></header><main><h1>透過ollama直接跑LLM大型語言模型：以llama3為例</h1><p>今天發生AI界驚天動地的大事，就是Meta公司正式發表開源LLM模型：<code>Llama 3</code>，第一時間跑去<code>hugging face</code>下載，發現竟然還要審核通過才放行，跑到他人fork出來的Meta-Llama-3-8B模型下載，發現竟然是爛掉，一怒之下切回ollama看有沒有官方整理好的，一看果然有<code>llama3:8B</code>版本，真是太佛心了。</p><p><img src=https://content.slashview.com/img/2024/20240419_01.jpg alt="" /></p><h2>透過ollama直接下載llama3模型</h2><p>切到docker運行的ollama console，直接下指令：</p><pre><code class=language-txt>ollama run llama3
</code></pre><p>接著ollama就會自動幫你接手下載所有編譯過的llama3模型檔。</p><p><img src=https://content.slashview.com/img/2024/20240419_02.jpg alt="" /></p><h2>運行llama3模型</h2><p>接著迫不及待的馬上在<code>ollama cli</code>上面輸入那段靈魂的拷問：</p><pre><code class=language-txt>>>> show 你是誰? 誰創造你?
</code></pre><p>看到這種回覆真的是太精確、太爽快了，相較先前那個<code>TAIDE</code>模型，簡直是將其按在地上磨擦。</p><p><img src=https://content.slashview.com/img/2024/20240419_03.jpg alt="" /></p><p>立刻轉頭透過<code>Open-WebUI</code>再度發出一次提問，這次請llama3用繁體中文回覆，回覆的也是很暢快又非常正確啊！</p><p><img src=https://content.slashview.com/img/2024/20240419_04.jpg alt="" /></p><h2>結論</h2><p>透過這篇文章我們可以學習到如何透過ollama官方封裝的方法，下載潮流之上的LLM大型語言模型，這個方法可以快速略過比較煩人的<code>hugging face</code>下載<code>guff檔</code>、複製與編譯工作，讓LLM的佈建過程變得方便又快速喔！</p><h3>相關連結</h3><ul><li><a href=/archive2024/20240418.html>不使用GPU在本機跑LLM大型語言模型：以TAIDE為例</a></li><li><a href=/archive2024/20240419.html>透過ollama直接跑LLM大型語言模型：以llama3為例</a></li></ul><h6>Windows NoGPU UseCPU Ollama HuggingFace LLM Model LocalHost ChatGPT Meta Facebook LLAMA3 llama3</h6></main><footer></footer><script src=/.file/site.js></script></body></html>