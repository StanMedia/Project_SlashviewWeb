<!DOCTYPE html><html><head><meta charset=utf-8 /><meta name=viewport content="width=device-width, initial-scale=1" /><link href=/.file/site.css rel=stylesheet /><script src=/.include/jquery/jquery.min.js></script></head><body><header></header><main><h1>ChatGPT：AI領域中的人類管家已經成形</h1><p>紀錄一下最近幾周來爆紅的ChatGPT自己的試用心得，ChatGPT是由非營利組織OpenAI所提出的產品，背後最大的金主是微軟（Microsoft），運行在微軟後端的Azure雲服務，相關的研究將在日後透過營利公司OpenAI LP的方式授權給微軟進行商業化的運作，可以預見尚未對外公開發表的Microsoft Designer應該也是基於OpenAI產生的衍生產品，以下針對ChatGPT進行簡單的感想與推論。</p><h2>AI之人類語言模型已經建立完成</h2><p>語言是人類溝通的根本，讓電腦能夠了解各國人類語言、解析並流暢的進行前後文溝通，在早期專用特定目的的AI根本就是不可能的事情（例如：只會下棋的AI、只會玩某種特定遊戲的AI...），而ChatGPT的出現令這些專用型的AI完全失色（大型語言模型；LLM；Large Language Model），因為人類最重要的溝通問題，在此刻已經站立穩固，接下來只剩迭代精進的問題而已。</p><p>以下節錄一段敝人跟ChatGPT對話的紀錄：</p><p><img src=https://content.slashview.com/img/2022/20221212_01.jpg alt="" /></p><p><img src=https://content.slashview.com/img/2022/20221212_02.jpg alt="" /></p><p>可以發現ChatGPT不僅確實懂得人類的語言，並且替換成使用語系端的文辭（程式碼→代碼），連程式碼他也可以對答如流，真的理解寫這段程式碼時希望他進行的工作，接著問他一些物理跟航太的知識也都回答的很完整，最後進行繼承先前記憶的前後文測試，請他幫忙修正一開始提的程式碼，ChatGPT也可以立即理解並真正的提出一個.NET Framework 4.0之後才釋出的方法，是一個非常實務的建議。</p><h2>ChatGPT引發的感想</h2><ol><li>我認為真的有一些工作要消失了，不需要情感的語言翻譯類或語言學習類的工作，例如語言教師，但不包含即席翻譯這種需要包括情感成分的翻譯工作。另外一想到人類透過類神經網路慢慢重建起希伯來聖經描述的巴比倫塔（Migdal Bāḇēl），心中也不免起了雞皮疙瘩，語言隔閡的轉捩點將自此發生了。</li><li>一旦迭代成熟並商品化廣泛使用後，社會會出現越來越多的孤僻、不擅長與人溝通的人，因此心理輔導的行業可能會愈發需求，但更諷刺的是這個輔導工作搞不好也是AI來取代。</li><li>很多人預言程式設計師要失業了，但我認為ChatGPT會是程式設計師未來最親密的朋友（a.k.a Copilot），StackOverflow目前封印ChatGPT的原因是因為他會隨機亂編程式碼，但我認為更可能的是要防止ChatGPT進行錯誤迭代的議題。</li><li>所謂的錯誤迭代就是基於錯誤的程式碼產生錯誤的理解，再去進行錯誤的解釋與衍生，形成錯上加錯。這個問題將會是ChatGPT未來最需要面對的問題，我們可以發現當前ChatGPT把網路存取的權限封印，就是怕眾多網友會透過網站的垃圾資料來影響ChatGPT的神經迴路，錯誤的訓練導致更偏差的結果，這是未來ChatGPT最難解的問題，因為遲早總是要開放連接網路的。</li><li>未來的人類需要訓練的是理解能力（語音與文字），學習的途徑有可能會被大幅翻轉，如果你能夠耐住心與ChatGPT對話並仔細閱讀他所描述的事情，假設ChatGPT的內容沒有被汙染的情況下，這個模型用來自我學習我認為足以，學校只剩下提供課綱（學習路徑）與學習多元性的功能。</li><li>人類與AI的關係自此正式走向的反折點，AI將慢慢的滲透與取代人類社會背後運作那個看不見的齒輪（人類集體的心智結果）。</li><li>AI每次的解析與運作需要成本，因此未來的數位落差也是需要關心的議題，AI會不會淪為付得起費用的族群的工具？</li><li>因為太貼身故擁有太多私密資訊，資訊安全、隱私權、政府的介入也都是值得關心的課題。</li><li>AI最後會成為每個人身邊最親密的朋友。你會跟他分享所有的事情，他就是你最貼身秘書，先前基於固定回應路徑的Siri、Alexa、Google Assistant、Cortana都將變成笑話，它會知道你所有一切的資訊與人格特質，甚至公司、法人組織也有AI所代表的角色。未來所有的人事物背後都有AI透過滲透來作為代表，那麼它就是你的靈魂、你的意識，想想就覺得恐怖且複雜：<ul><li>參考下圖佛洛伊德（冰山模型；Iceberg Model），牽扯到哲學的終極問題：我是誰？本我（id）、自我（ego）、超我（superego）？先有意識還是先有行為？意識（靈魂）存在於哪裡？AI是不是默默的取代了你的意識？</li><li>AI從小與你相伴，給出99.9%你認可的決策或建議，形成絕對的熟悉＞絕對的信任＞絕對的依賴。那麼未來你會每次認真地審視並拒絕那0.1%的錯誤嗎？如果那0.1%的錯誤是「故意」產生的呢？其餘99.9%就真的是對的事情嗎？真的是你的意識下決定的作法嗎？還是你早已被潛移默化成AI想要你成為的樣子？</li><li>於是，提供超大型AI服務的企業、組織有多少用戶，就可以操控多少用戶，這會受到監管嗎？誰來監管這個監管？你有權力選擇監管者嗎？</li><li>在法律上犯罪者可能會因為精神問題（犯罪當下沒有意識）而免除罪罰，未來若有人依賴AI建議而犯罪，可以主張自己只是執行者（肉體）嗎？</li></ul></li></ol><p><img src=https://content.slashview.com/img/2022/20221212_03.jpg alt="" /></p><h3>相關連結</h3><ul><li><a href=/archive2013/20130925.html>馬斯洛需求層次論（Maslow's Hierarchy of Needs Theory）</a></li><li><a href=/archive2025/20250728.html>迪爾茲邏輯層次模型（Dilts' Logical Levels）</a></li><li><a href=/archive2022/20221212.html>ChatGPT：AI領域中的人類管家已經成形</a> / 佛洛伊德（冰山模型；Iceberg Model）</li></ul><h3>Update 2023-02-07</h3><p>這篇文章主要揣述ChatGPT在人類世界的AI創立了一個絕對無庸置疑的里程碑，當下Google還在嘴硬說著「Google當然也具有ChatGPT的類似能力，但如果出現問題，付出的代價會更高，會影響公司聲譽，因為人們更相信他們從Google得到的答案，因此不該冒進。」之類的話語，事實上卻偷偷開啟CodeRed（紅色警報）專案強力對應，畢竟持盈保泰的搜尋廣告業務如果被搶走就糟了。</p><p>Google公司於2023-02-06果然釋放出全新的聊天AI對應，一個名為Bard的AI聊天機器人被推出搶市，如此動作更加證明ChatGPT已為網際網路建立了一個嶄新且接受度極高的應用（兩個月內活耀用戶數突破一億大關），Google CEO Sundar Pichai撰寫的Bard AI聊天機器人公開推送全文如附件：<a href=https://content.slashview.com/file/20221212/An%20important%20next%20step%20on%20our%20AI%20journey.pdf>An important next step on our AI journey</a></p><p>敝人認為廣告還是會有，只是會以某種方式出現在AI對話搜尋領域，例如使用AI運算後一段時間強迫你看廣告、在AI聊天的過程中插入廣告之類的...，畢竟AI每次運算都是一次資源的耗用，沒有長久可變現模式的投入參與，這樣的服務與應用是不會長久的。</p><h6>AI Chat ChatGPT LLM LargeLanguageModel Thoughts Vision Ideas Opinion 感想 願景 想法 觀點</h6></main><footer></footer><script src=/.file/site.js></script></body></html>